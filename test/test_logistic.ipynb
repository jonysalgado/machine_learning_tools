{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import nltk\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import random\r\n",
    "import re\r\n",
    "import string\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "from nltk.tokenize import TweetTokenizer\r\n",
    "import numpy as np\r\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "class LogisticRegression_:\r\n",
    "\r\n",
    "\r\n",
    "    def __init__(self, alpha: float = 0.17):\r\n",
    "        self.alpha = alpha\r\n",
    "        pass\r\n",
    "\r\n",
    "    def fit(self, X : np.array, y : np.array):\r\n",
    "\r\n",
    "        self.n_feactures = X.shape[1]\r\n",
    "        self.theta = np.random.randn(self.n_feactures)\r\n",
    "        self.length = X.shape[0]\r\n",
    "        sum = np.zeros(self.n_feactures)\r\n",
    "        for i in range(self.length):\r\n",
    "            sum = self.update_sum(sum, X, y, i)\r\n",
    "        \r\n",
    "        sum = -self.alpha* sum/self.length\r\n",
    "        \r\n",
    "        self.theta = np.add(self.theta, sum)\r\n",
    "\r\n",
    "\r\n",
    "    def update_sum(self, sum : np.array, X : np.array, y : np.array, line: int):\r\n",
    "        for i in range(self.n_feactures):\r\n",
    "            sum[i] += (self.sigmoid(np.sum(np.multiply(X[line, :],self.theta))) - y[line]) * X[line, i]\r\n",
    "\r\n",
    "        return sum\r\n",
    "\r\n",
    "    def sigmoid(self, x):\r\n",
    "        return 1/(1 + np.exp(-1*x))\r\n",
    "\r\n",
    "\r\n",
    "    def predict(self, X: np.array):\r\n",
    "\r\n",
    "        y = np.zeros(X.shape[0])\r\n",
    "        for line in range(X.shape[0]):\r\n",
    "            y[line] = self.sigmoid(np.multiply(X[line, :],  self.theta))\r\n",
    "\r\n",
    "        return y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df = pd.read_csv(\"train.csv\")\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "all_disaster_tweets = df[df[\"target\"] == 1][\"text\"].to_list()\r\n",
    "all_non_disaster_tweets = df[df[\"target\"] == 0][\"text\"].to_list()\r\n",
    "tweets = all_disaster_tweets + all_non_disaster_tweets\r\n",
    "labels = np.append(np.ones((len(all_disaster_tweets))), np.zeros((len(all_non_disaster_tweets))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "stopwords_english = stopwords.words('english') \r\n",
    "def process_tweet(tweet):\r\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\r\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\r\n",
    "    tweet = re.sub(r'#', '', tweet)\r\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\r\n",
    "                               reduce_len=True)\r\n",
    "    tweet = tokenizer.tokenize(tweet)\r\n",
    "    tweets_clean = []\r\n",
    "\r\n",
    "    for word in tweet: # Go through every word in your tokens list\r\n",
    "        if (word not in stopwords_english and  # remove stopwords\r\n",
    "            word not in string.punctuation):  # remove punctuation\r\n",
    "            tweets_clean.append(word)\r\n",
    "\r\n",
    "    stemmer = PorterStemmer() \r\n",
    "    tweets_stem = [] \r\n",
    "\r\n",
    "    for word in tweets_clean:\r\n",
    "        stem_word = stemmer.stem(word)  # stemming word\r\n",
    "        tweets_stem.append(stem_word)  # append to the list\r\n",
    "    \r\n",
    "    return tweets_stem    \r\n",
    "\r\n",
    "def build_freqs(tweets, ys):\r\n",
    "    freqs = {}\r\n",
    "    yslist = np.squeeze(ys).tolist()\r\n",
    "\r\n",
    "    for y, tweet in zip(yslist, tweets):\r\n",
    "        for word in process_tweet(tweet):\r\n",
    "            pair = (word, y)\r\n",
    "            freqs[pair] = freqs.get(pair, 0) + 1\r\n",
    "\r\n",
    "    return freqs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "freqs = build_freqs(tweets, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_dis = all_disaster_tweets[:2500]\r\n",
    "train_non = all_non_disaster_tweets[:3000]\r\n",
    "train_tweets = train_dis + train_non\r\n",
    "labels = np.append(np.ones((len(train_dis))), np.zeros((len(train_non))))\r\n",
    "bias = np.ones(len(labels))\r\n",
    "logistic_features = pd.DataFrame({'bias': bias})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def process_logistic_regression(tweet, freqs):\r\n",
    "    non_dissaster_sum = 0\r\n",
    "    dissaster_sum = 0\r\n",
    "    for word in process_tweet(tweet):\r\n",
    "        pair = (word, 0)\r\n",
    "        non_dissaster_sum += freqs.get(pair, 0)\r\n",
    "        pair = (word, 1)\r\n",
    "        dissaster_sum += freqs.get(pair, 0)\r\n",
    "\r\n",
    "    return dissaster_sum, non_dissaster_sum"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "dissaster_list = []\r\n",
    "non_dissaster_list = []\r\n",
    "for tweet in train_tweets:\r\n",
    "    process_logistic = process_logistic_regression(tweet, freqs)\r\n",
    "    dissaster_list.append(process_logistic[0])\r\n",
    "    non_dissaster_list.append(process_logistic[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "logistic_features['dissaster'] = dissaster_list\r\n",
    "logistic_features['non_dissaster'] = non_dissaster_list\r\n",
    "logistic_features['label'] = labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "logistic_features.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   bias  dissaster  non_dissaster  label\n",
       "0   1.0        149            141    1.0\n",
       "1   1.0        393            117    1.0\n",
       "2   1.0        248            123    1.0\n",
       "3   1.0        425            143    1.0\n",
       "4   1.0        192            211    1.0\n",
       "5   1.0        621            164    1.0\n",
       "6   1.0        582            221    1.0\n",
       "7   1.0        996            840    1.0\n",
       "8   1.0        356            227    1.0\n",
       "9   1.0        778            716    1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>dissaster</th>\n",
       "      <th>non_dissaster</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>149</td>\n",
       "      <td>141</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>393</td>\n",
       "      <td>117</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>248</td>\n",
       "      <td>123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>425</td>\n",
       "      <td>143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>192</td>\n",
       "      <td>211</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>621</td>\n",
       "      <td>164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>582</td>\n",
       "      <td>221</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>996</td>\n",
       "      <td>840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>356</td>\n",
       "      <td>227</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>778</td>\n",
       "      <td>716</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X = logistic_features[['bias', 'dissaster', 'non_dissaster']].values # Get only the numerical values of the dataframe\r\n",
    "y = logistic_features['label'].values; # Put in Y the corresponding labels or sentiments\r\n",
    "\r\n",
    "print(X.shape) # Print the shape of the X part\r\n",
    "print(X) # Print some rows of X"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5500, 3)\n",
      "[[  1. 149. 141.]\n",
      " [  1. 393. 117.]\n",
      " [  1. 248. 123.]\n",
      " ...\n",
      " [  1.  73. 300.]\n",
      " [  1. 169. 358.]\n",
      " [  1.  15.  89.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "clf = LogisticRegression().fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "theta = clf.coef_[0]\r\n",
    "theta, np.sqrt(theta[0]**2 + theta[1]**2  + theta[2]**2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-0.10902314,  0.0078544 , -0.00800717]), 0.10959858938029954)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "test = LogisticRegression_(alpha=0.1)\r\n",
    "test.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "test.theta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1.35769027, -8.46564723, -8.58409381])"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}